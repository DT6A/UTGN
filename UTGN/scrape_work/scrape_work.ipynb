{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-18T07:10:26.266546Z",
     "start_time": "2019-07-18T07:10:23.956566Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T07:59:37.566043Z",
     "start_time": "2019-06-24T07:59:37.559783Z"
    }
   },
   "outputs": [],
   "source": [
    "class switch(object):\n",
    "    \"\"\"Switch statement for Python, based on recipe from Python Cookbook.\"\"\"\n",
    "\n",
    "    def __init__(self, value):\n",
    "        self.value = value\n",
    "        self.fall = False\n",
    "\n",
    "    def __iter__(self):\n",
    "        \"\"\"Return the match method once, then stop\"\"\"\n",
    "        yield self.match\n",
    "        raise StopIteration\n",
    "    \n",
    "    def match(self, *args):\n",
    "        \"\"\"Indicate whether or not to enter a case suite\"\"\"\n",
    "        if self.fall or not args:\n",
    "            return True\n",
    "        elif self.value in args: # changed for v1.5\n",
    "            self.fall = True\n",
    "            return True\n",
    "        else:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T08:05:28.629950Z",
     "start_time": "2019-06-24T08:05:28.613196Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "55\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "generator raised StopIteration",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-0f532a556a9d>\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mStopIteration\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-cf0230672d31>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"hi\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mswitch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"hi\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dfsd'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: generator raised StopIteration"
     ]
    }
   ],
   "source": [
    "# test_dict = {\"hi\": 5, \"hey\": 3}\n",
    "# test_dict = [\"hi\", \"hey\"]\n",
    "test_dict = \"hi\"\n",
    "\n",
    "for case in switch(test_dict):\n",
    "    print(case(\"hi\"))\n",
    "    if case('dfsd'):\n",
    "        print(55)\n",
    "    elif case('hi'):\n",
    "        print(23423)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T01:16:02.620911Z",
     "start_time": "2019-06-25T01:16:02.462672Z"
    }
   },
   "outputs": [],
   "source": [
    "# https://stats.stackexchange.com/questions/330176/what-is-the-output-of-a-tf-nn-dynamic-rnn\n",
    "tf.reset_default_graph()\n",
    "n_steps = 2\n",
    "n_inputs = 3\n",
    "n_neurons = 5\n",
    "\n",
    "X = tf.placeholder(dtype=tf.float32, shape=[None, n_steps, n_inputs])\n",
    "seq_length = tf.placeholder(tf.int32, [None])\n",
    "\n",
    "basic_cell = tf.nn.rnn_cell.BasicRNNCell(num_units=n_neurons)\n",
    "outputs, states = tf.nn.dynamic_rnn(basic_cell, X, sequence_length=seq_length, dtype=tf.float32)\n",
    "\n",
    "X_batch = np.array([\n",
    "  # t = 0      t = 1\n",
    "  [[0, 1, 2], [9, 8, 7]], # instance 0\n",
    "  [[3, 4, 5], [0, 0, 0]], # instance 1\n",
    "  [[6, 7, 8], [6, 5, 4]], # instance 2\n",
    "  [[9, 0, 1], [3, 2, 1]], # instance 3\n",
    "])\n",
    "seq_length_batch = np.array([2, 1, 2, 2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T01:16:03.966640Z",
     "start_time": "2019-06-25T01:16:03.791563Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 2, 5)\n",
      "\n",
      "(4, 5)\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    outputs_val, states_val = sess.run([outputs, states],\n",
    "                                       feed_dict={\n",
    "                                           X: X_batch,\n",
    "                                           seq_length: seq_length_batch\n",
    "                                       })\n",
    "\n",
    "    print(outputs_val.shape)\n",
    "    print()\n",
    "    print(states_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-18T07:10:38.116972Z",
     "start_time": "2019-07-18T07:10:38.098298Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 5, 6, 7)\n",
      "(4, 6, 7)\n",
      "(4, 5, 7, 6)\n",
      "Tensor(\"random_uniform:0\", shape=(4, 5, 6, 7), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "# x = tf.constant([[1., 1.], [2., 2.]])\n",
    "x = tf.random.uniform((4,5,6,7))\n",
    "y = tf.reduce_mean(x,axis=1)\n",
    "z = tf.transpose(x, perm=[0,1,3,2])\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(x.shape)\n",
    "    print(y.shape)\n",
    "    print(z.shape)\n",
    "    print(x)\n",
    "# x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-28T01:23:11.562573Z",
     "start_time": "2019-06-28T01:23:11.552585Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'functions_on_devices': {'/cpu:0': ['point_to_coordinate']},\n",
       " 'default_device': ''}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "computing = {\n",
    "    'functions_on_devices': {'/cpu:0': ['point_to_coordinate']},\n",
    "    'default_device': ''\n",
    "    \n",
    "}\n",
    "{k: computing[k] for k in ('functions_on_devices', 'default_device')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-28T04:03:17.956549Z",
     "start_time": "2019-06-28T04:03:17.910264Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(\"TENLYFQSMGLRTVEMKKGPTDSLGISIAGGVGSPLGDVPIFIAMMHPTGVAAQTQKLRVGDRIVTICGTSTEGMTHTQAVNLLKNASGSIEMQVVAGGDVSETSV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-28T04:03:46.416195Z",
     "start_time": "2019-06-28T04:03:46.410102Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(\"----------++++++++----++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++--------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Create PDB file for predicted and actual 3D structure.\n",
    "\"\"\"\n",
    "\n",
    "from ast import literal_eval\n",
    "import argparse\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from Bio.PDB.PDBParser import PDBParser\n",
    "from Bio.PDB.Atom import Atom\n",
    "from Bio.PDB.Residue import Residue\n",
    "from Bio.PDB.Chain import Chain\n",
    "from Bio.PDB.Model import Model\n",
    "from Bio.PDB.Structure import Structure\n",
    "from Bio.PDB import PDBIO\n",
    "\n",
    "NUM_DIMENSIONS = 3\n",
    "AA_LETTERS = {\n",
    "    'A': 'ALA',\n",
    "    'R': 'ARG',\n",
    "    'N': 'ASN',\n",
    "    'D': 'ASP',\n",
    "    'C': 'CYS',\n",
    "    'E': 'GLU',\n",
    "    'Q': 'GLN',\n",
    "    'G': 'GLY',\n",
    "    'H': 'HIS',\n",
    "    'I': 'ILE',\n",
    "    'L': 'LEU',\n",
    "    'K': 'LYS',\n",
    "    'M': 'MET',\n",
    "    'F': 'PHE',\n",
    "    'P': 'PRO',\n",
    "    'S': 'SER',\n",
    "    'T': 'THR',\n",
    "    'W': 'TRP',\n",
    "    'Y': 'TYR',\n",
    "    'V': 'VAL'\n",
    "}\n",
    "\n",
    "\n",
    "class Protein:\n",
    "    \"\"\"Stores amino acid sequence and structure.\n",
    "\n",
    "    Attributes:\n",
    "        id_: name of protein\n",
    "        primary: string of amino acid sequence\n",
    "        actual_tertiary: np array\n",
    "        mask: np array of 1 and 0s\n",
    "        pred_tertiary: np array\n",
    "    \"\"\"\n",
    "\n",
    "    _aa_dict = {\n",
    "        'A': '0',\n",
    "        'C': '1',\n",
    "        'D': '2',\n",
    "        'E': '3',\n",
    "        'F': '4',\n",
    "        'G': '5',\n",
    "        'H': '6',\n",
    "        'I': '7',\n",
    "        'K': '8',\n",
    "        'L': '9',\n",
    "        'M': '10',\n",
    "        'N': '11',\n",
    "        'P': '12',\n",
    "        'Q': '13',\n",
    "        'R': '14',\n",
    "        'S': '15',\n",
    "        'T': '16',\n",
    "        'V': '17',\n",
    "        'W': '18',\n",
    "        'Y': '19'\n",
    "    }\n",
    "    _mask_dict = {'-': '0', '+': '1'}\n",
    "    _aa_dict = dict((v, k) for k, v in _aa_dict.items())\n",
    "\n",
    "    def __init__(self, id_, primary, actual_tertiary, mask, pred_tertiary):\n",
    "        self.id_ = id_\n",
    "        self.primary = primary\n",
    "        self.actual_tertiary = actual_tertiary\n",
    "        self.pred_tertiary = pred_tertiary\n",
    "        self.mask = mask\n",
    "        self.int_to_aa()\n",
    "\n",
    "    def int_to_aa(self):\n",
    "        integers = list(self.primary.astype('str'))\n",
    "        aa = \"\".join([self._aa_dict[integer] for integer in integers])\n",
    "        self.primary = aa\n",
    "\n",
    "\n",
    "def read_tertiary_file(path):\n",
    "    \"\"\"Read .tertiary file\"\"\"\n",
    "\n",
    "    coords = np.transpose(np.loadtxt(path))\n",
    "\n",
    "    return coords\n",
    "\n",
    "\n",
    "def read_and_decode(filename_queue):\n",
    "    \"\"\"Parse a single instance of a tf record.\n",
    "    \n",
    "    Args:\n",
    "        filename_queue: tf queue\n",
    "        \n",
    "    Returns:\n",
    "        id_:tf tensor\n",
    "        primary: tf tensor\n",
    "        tertiary: tf tensor\n",
    "        mask: tf tensor\n",
    "    \"\"\"\n",
    "\n",
    "    reader = tf.TFRecordReader()\n",
    "    _, serialized_example = reader.read(filename_queue)\n",
    "\n",
    "    context, features = tf.parse_single_sequence_example(\n",
    "        serialized_example,\n",
    "        context_features={'id': tf.FixedLenFeature((1, ), tf.string)},\n",
    "        sequence_features={\n",
    "            'primary':\n",
    "            tf.FixedLenSequenceFeature((1, ), tf.int64),\n",
    "            'tertiary':\n",
    "            tf.FixedLenSequenceFeature((NUM_DIMENSIONS, ),\n",
    "                                       tf.float32,\n",
    "                                       allow_missing=True),\n",
    "            'mask':\n",
    "            tf.FixedLenSequenceFeature((1, ), tf.float32, allow_missing=True)\n",
    "        })\n",
    "\n",
    "    id_ = context['id'][0]\n",
    "    primary = tf.to_int32(features['primary'][:, 0])\n",
    "    tertiary = features['tertiary']\n",
    "    mask = features['mask'][:, 0]\n",
    "    return id_, primary, tertiary, mask\n",
    "\n",
    "\n",
    "def tf_record_to_dict(tf_path, tertiary_dir):\n",
    "    \"\"\"Convert tfrecord to a list of Proteins.\n",
    "    \n",
    "    Args:\n",
    "        tf_path: path to tf record\n",
    "        tertiary_dir: directory that holds .tertiary files\n",
    "        \n",
    "    Returns:\n",
    "        list of Proteins\n",
    "    \"\"\"\n",
    "\n",
    "    tf.reset_default_graph()\n",
    "    with tf.Session() as sess:\n",
    "        proteins = []\n",
    "        init_op = tf.group(tf.global_variables_initializer(),\n",
    "                           tf.local_variables_initializer())\n",
    "        sess.run(init_op)\n",
    "\n",
    "        filename_queue = tf.train.string_input_producer([tf_path],\n",
    "                                                        shuffle=False)\n",
    "\n",
    "        attributes = read_and_decode(filename_queue)\n",
    "        coord = tf.train.Coordinator()\n",
    "        threads = tf.train.start_queue_runners(coord=coord)\n",
    "\n",
    "        size = sum(1 for _ in tf.python_io.tf_record_iterator(tf_path))\n",
    "        for i in range(size):\n",
    "\n",
    "            id_, primary, tertiary, mask = sess.run(list(attributes))\n",
    "            id_ = id_.decode(\"utf-8\")\n",
    "            try:\n",
    "                pred_coords = read_tertiary_file(tertiary_dir + id_ +\n",
    "                                                 '.tertiary')\n",
    "            except (FileNotFoundError, OSError):\n",
    "                pred_coords = np.array([])\n",
    "            protein = Protein(id_, primary, tertiary, mask, pred_coords)\n",
    "            proteins.append(protein)\n",
    "        coord.request_stop()\n",
    "        coord.join(threads)\n",
    "\n",
    "        return proteins\n",
    "\n",
    "\n",
    "def create_pdb_file(protein, save_dir):\n",
    "    \"\"\"Create a PDB file from a Protein and return the structure.\n",
    "    \n",
    "    Args:\n",
    "        protein: Protein\n",
    "        save_dir: directory to save pdb files\n",
    "        \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    def create_structure(coords, pdb_type, remove_masked):\n",
    "        \"\"\"Create the structure.\n",
    "        \n",
    "        Args:\n",
    "            coords: 3D coordinates of structure\n",
    "            pdb_type: predict or actual structure\n",
    "            remove_masked: whether to include masked atoms. If false, the masked atoms \n",
    "                  have coordinates of [0,0,0].\n",
    "                  \n",
    "        Returns:\n",
    "            structure\n",
    "        \"\"\"\n",
    "\n",
    "        name = protein.id_\n",
    "        structure = Structure(name)\n",
    "        model = Model(0)\n",
    "        chain = Chain('A')\n",
    "        for i, residue in enumerate(protein.primary):\n",
    "            residue = AA_LETTERS[residue]\n",
    "            if int(protein.mask[i]) == 1 or remove_masked == False:\n",
    "                new_residue = Residue((' ', i + 1, ' '), residue, '    ')\n",
    "                j = 3 * i\n",
    "                atom_list = ['N', 'CA', 'CB']\n",
    "                for k, atom in enumerate(atom_list):\n",
    "                    new_atom = Atom(name=atom,\n",
    "                                    coord=coords[j + k, :],\n",
    "                                    bfactor=0,\n",
    "                                    occupancy=1,\n",
    "                                    altloc=' ',\n",
    "                                    fullname=\" {} \".format(atom),\n",
    "                                    serial_number=0)\n",
    "                    new_residue.add(new_atom)\n",
    "                chain.add(new_residue)\n",
    "        model.add(chain)\n",
    "        structure.add(model)\n",
    "        io = PDBIO()\n",
    "        io.set_structure(structure)\n",
    "        io.save(save_dir + name + '_' + pdb_type + '.pdb')\n",
    "        return structure\n",
    "\n",
    "    coords = np.around(protein.actual_tertiary, 1)\n",
    "    coords = coords / 100\n",
    "    create_structure(coords, \"actual\", remove_masked=True)\n",
    "\n",
    "    if protein.pred_tertiary.size != 0:\n",
    "        coords = np.around(protein.pred_tertiary, 1)\n",
    "        coords = coords / 100\n",
    "        create_structure(coords, \"pred\", remove_masked=False)\n",
    "\n",
    "\n",
    "def create_pdb_files(proteins, save_dir):\n",
    "    \"\"\"Create multiple pdb files\n",
    "    \n",
    "    Args:\n",
    "        proteins: list of Proteins\n",
    "        save_dir: directory to save pdb files\n",
    "    \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    for protein in proteins:\n",
    "        create_pdb_file(protein, save_dir)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser(description=\"Create PDB structure\")\n",
    "\n",
    "    parser.add_argument('tf_record', default='.', help='Path to tf record')\n",
    "\n",
    "    parser.add_argument('tertiary_dir',\n",
    "                        default='.',\n",
    "                        help='Directory that contains .tertiary files')\n",
    "\n",
    "    parser.add_argument('pdb_dir',\n",
    "                        default='.',\n",
    "                        help='Directory to save PDB files')\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    proteins = tf_record_to_dict(args.tf_record, args.tertiary_dir)\n",
    "\n",
    "    create_pdb_files(proteins, args.pdb_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
